{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeremias Junior\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import bs4 as bs\n",
    "import ftplib\n",
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import urllib.request\n",
    "import pip\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diff(url, file_name):\n",
    "    '''\n",
    "    Verifica se o arquivo no servidor existe no disco e se ele tem o mesmo\n",
    "    tamanho no servidor.\n",
    "    '''\n",
    "    if not os.path.isfile(file_name):\n",
    "        return True # ainda nao foi baixado\n",
    "\n",
    "    response = requests.head(url)\n",
    "    new_size = int(response.headers.get('content-length', 0))\n",
    "    old_size = os.path.getsize(file_name)\n",
    "    if new_size != old_size:\n",
    "        os.remove(file_name)\n",
    "        return True # tamanho diferentes\n",
    "\n",
    "    return False # arquivos sao iguais\n",
    "\n",
    "def makedirs(path):\n",
    "    '''\n",
    "    cria path caso seja necessario\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def getEnv(env):\n",
    "    return os.getenv(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the directories for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_env = r'C:\\Users\\Jeremias Junior\\Documents\\GitHub\\gov_data'\n",
    "\n",
    "dados_rf = 'http://200.152.38.155/CNPJ/'\n",
    "\n",
    "raw_files = r'C:\\Users\\Jeremias Junior\\Documents\\GitHub\\gov_data\\data\\raw_files'\n",
    "extracted_files = r'C:\\Users\\Jeremias Junior\\Documents\\GitHub\\gov_data\\data\\extracted_files'\n",
    "\n",
    "raw_html = urllib.request.urlopen(dados_rf)\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "# Formatar pÃ¡gina e converter em string\n",
    "page_items = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "html_str = str(page_items)\n",
    "\n",
    "Files = []\n",
    "text = '.zip'\n",
    "for m in re.finditer(text, html_str):\n",
    "    i_start = m.start()-40\n",
    "    i_end = m.end()\n",
    "    i_loc = html_str[i_start:i_end].find('href=')+6\n",
    "    Files.append(html_str[i_start+i_loc:i_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_l = 0\n",
    "print('unzipping files')\n",
    "for l in Files:\n",
    "\n",
    "    try:\n",
    "        i_l += 1\n",
    "        \n",
    "        print(str(i_l) + ' - ' + l)\n",
    "        full_path = os.path.join(raw_files, l)\n",
    "        with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extracted_files)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up files and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_start = time.time()\n",
    "\n",
    "items = [name for name in os.listdir(extracted_files) if name.endswith('')]\n",
    "\n",
    "files = dict()\n",
    "\n",
    "files['empresa'] = list()\n",
    "files['estabeleciemnto'] = list()\n",
    "files['socios'] = list()\n",
    "files['simples'] = list()\n",
    "files['cnae'] = list()\n",
    "files['moti'] = list()\n",
    "files['munic'] = list()\n",
    "files['natju'] = list()\n",
    "files['pais'] = list()\n",
    "files['quals'] = list()\n",
    "\n",
    "for i in range(len(items)):\n",
    "\n",
    "    if items[i].find('EMPRE') > -1:\n",
    "        files['empresa'].append(items[i])\n",
    "    if items[i].find('ESTABELE') > -1:\n",
    "        files['estabeleciemnto'].append(items[i])\n",
    "    if items[i].find('SOCIO') > -1:\n",
    "        files['socios'].append(items[i])\n",
    "    if items[i].find('SIMPLES') > -1:\n",
    "        files['simples'].append(items[i])\n",
    "    if items[i].find('CNAE') > -1:\n",
    "        files['cnae'].append(items[i])\n",
    "    if items[i].find('MOTI') > -1:\n",
    "        files['moti'].append(items[i])\n",
    "    if items[i].find('MUNIC') > -1:\n",
    "        files['munic'].append(items[i])\n",
    "    if items[i].find('NATJU') > -1:\n",
    "        files['natju'].append(items[i])\n",
    "    if items[i].find('PAIS') > -1:\n",
    "        files['pais'].append(items[i])\n",
    "    if items[i].find('QUALS') > -1:   \n",
    "        files['quals'].append(items[i])\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "\n",
    "               \n",
    "conn = pyodbc.connect(driver='{SQL Server}', \n",
    "                      server='(local)', \n",
    "                      database='gov_db',               \n",
    "                      trusted_connection='yes')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading :  K3241.K03200Y1.D20910.EMPRECSV\n",
      "['00000000', 'BANCO DO BRASIL SA', '2038', '10', '90000023475,34', '05', 'nan'] <class 'type'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jeremias Junior\\Documents\\GitHub\\gov_data\\main.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jeremias%20Junior/Documents/GitHub/gov_data/main.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mprint\u001b[39m(empresa\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()[\u001b[39m0\u001b[39m], \u001b[39mtype\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jeremias%20Junior/Documents/GitHub/gov_data/main.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mfor\u001b[39;00m values \u001b[39min\u001b[39;00m empresa\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jeremias%20Junior/Documents/GitHub/gov_data/main.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         cursor\u001b[39m.\u001b[39;49mexecute(insertdata_query, values)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jeremias%20Junior/Documents/GitHub/gov_data/main.ipynb#X14sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jeremias%20Junior/Documents/GitHub/gov_data/main.ipynb#X14sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m empresa\u001b[39m.\u001b[39mhead(\u001b[39m20\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "table_name = 'empresa'\n",
    "table_columns = ['cnpj_basico', \n",
    "                       'razao_social', \n",
    "                       'natureza_juridica', \n",
    "                       'qualificacao_responsavel', \n",
    "                       'capital_social', \n",
    "                       'porte_empresa', \n",
    "                       'ente_federativo_responsavel']\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS \"empresa\";')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "create_table= f\"CREATE TABLE {table_name} ({', '.join([f'{col} VARCHAR(255)' for col in table_columns])})\"\n",
    "cursor.execute(create_table)\n",
    "cursor.commit()\n",
    "\n",
    "\n",
    "insertdata_query = f\"INSERT INTO {table_name} ({', '.join(table_columns)}) VALUES ({', '.join(['?'] * len(table_columns))})\"\n",
    "\n",
    "\n",
    "for i in range(0, len(files['empresa'])):\n",
    "    print('loading : ',files['empresa'][i])\n",
    "\n",
    "    empresa = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6])\n",
    "    empresa_dtypes = {0: 'object', 1: 'object', 2: 'object', 3: 'object', 4: 'object', 5: 'object', 6: 'object'}\n",
    "    extracted_file_path = os.path.join(extracted_files, files['empresa'][i])\n",
    "\n",
    "    empresa = pd.read_csv(filepath_or_buffer=extracted_file_path,\n",
    "                          sep=';',\n",
    "                          #nrows=100,\n",
    "                          skiprows=0,\n",
    "                          header=None,\n",
    "                          dtype=empresa_dtypes,\n",
    "                          encoding='latin-1',\n",
    "                        )\n",
    "    \n",
    "    empresa = empresa.reset_index()\n",
    "\n",
    "    del empresa['index']\n",
    "\n",
    "    empresa.columns = ['cnpj_basico', \n",
    "                       'razao_social', \n",
    "                       'natureza_juridica', \n",
    "                       'qualificacao_responsavel', \n",
    "                       'capital_social', \n",
    "                       'porte_empresa', \n",
    "                       'ente_federativo_responsavel']\n",
    "    \n",
    "    #empresa['capital_social'] = empresa['capital_social'].apply(lambda x: x.replace(',','.'))\n",
    "    empresa['ente_federativo_responsavel'] = empresa['ente_federativo_responsavel'] .astype(str)\n",
    "    \n",
    "    for values in empresa.values.tolist():\n",
    "        cursor.execute(insertdata_query, values)\n",
    "    print(i)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "empresa.head(20)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['36627979',\n",
       " 'LORENA MARIA DE BRITO CAMARGO 09776918700',\n",
       " '2135',\n",
       " '50',\n",
       " '4000,00',\n",
       " '01',\n",
       " 'nan']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empresa.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
